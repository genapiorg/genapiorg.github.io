{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Generative AI API","text":"<p>GenAPI provides a helper API, ready to integrate functions repository, and a quickstart cookbook for building Generative AI Apps.</p> <p></p> <p>Our launch recipe is using OpenAI Functions with Climate APIs available as a Jupyter notebook. We use this notebook to illustrate a number of fundamental concepts. For example, we demonstrate how to use the helper API to simulate a chat experience within a Jupyter notebook with a simple statement. We also demonstrate with the accompanying Climate API examples how to write a function and crisp specification which can be consumed by the LLM with accuracy.</p>"},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#functions","title":"Functions","text":"<ul> <li>OpenAI Functions with Climate API</li> </ul>"},{"location":"functions/openai-functions-with-climate-apis/","title":"OpenAI Functions with Climate APIs","text":"<p>Most popular user experience based on Large Language Models is the chat experience popularized by ChatGPT. Bard and Bing use cases of LLM follow a specialization of this chat experience in the form of questions and answers (Q&amp;A). When enterprise build apps using LLMs, they are likely to use a combination of chat and Q&amp;A experiences. These apps are more useful when they are able to integrate existing apps and services activated based on the context of the chat or Q&amp;A experience. Think of this as a conversation with your assistant about a certain topic. At some point you may suggest actions for the assistant to execute based on the context of the conversation. This is where the concept of functions come in. Functions are a way to specify actions that can be executed based on the context of the conversation.</p> <p>OpenAI Functions were introduced in July 2023 as a way for developers to have GPT 4 and GPT 3.5 models identify when to process user inputs and extract JSON arguments matching function specs specified in the chat context.</p> <p>API Tips</p> <p>You can specify a functions in a similar format as a typical function documentation describing the function name, description, arguments, and return values. GenAPI project structure recommends writing the function spec next to the function definition so that it is easy to keep both in sync with any future changes.</p>","tags":["Functions"]},{"location":"functions/openai-functions-with-climate-apis/#helper-apis-and-functions-repository","title":"Helper APIs and Functions Repository","text":"<p>GenAPI helpers include wrappers for OpenAI APIs to maintain conversation context within a multi-step chat and perform question and action in a single-step dialog. We also include helpers for simulating chat like experiemce within a notebook and evaluating function calling within a conversation. </p> Importing GenAPI Helper APIs and Functions Repository<pre><code>from helpers import genapi, notebook\nfrom apis import climate\n</code></pre> <p>GenAPI also provides a functions repository with a number of functions that can be used to build Generative AI Apps. The functions repository is organized into a number of categories like the one we are launching with for climate APIs which include weather and air quality functions. We can add these functions to our project like so.</p> Adding Climate Functions Repository<pre><code>functions = climate.functions\nfunction_names = {\n    \"weather\": climate.weather,\n    \"air_quality\": climate.air_quality\n}\n</code></pre>","tags":["Functions"]},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#functions","title":"Functions","text":"<ul> <li>OpenAI Functions with Climate API</li> </ul>"}]}